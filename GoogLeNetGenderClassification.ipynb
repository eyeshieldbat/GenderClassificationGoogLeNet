{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cN9RKKN5UMYf"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import time\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_path='drive/MyDrive/Project 1: Face Recognition/Datasets'\n",
        "image_folder_path=os.path.join(data_path, \"Images\")"
      ],
      "metadata": {
        "id": "VrnZErbHUOkA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "aET5hPK4UaD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(data_path)"
      ],
      "metadata": {
        "id": "GvAHVjv3UfYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(os.path.join(data_path, 'gender_classification.csv'))\n",
        "df.columns=[\"image_path\",\"Male\"]\n",
        "df"
      ],
      "metadata": {
        "id": "Ep-StnvLUjcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data process male or female\n",
        "df_male = df.loc[df['Male']==1]\n",
        "df_female = df.loc[df['Male']==0]"
      ],
      "metadata": {
        "id": "-qGQcli6UnI0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Set Data Train and Test**"
      ],
      "metadata": {
        "id": "KlSyrtz6V1j2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def SplitDataset(split_ratio):\n",
        "    # Split the data male into train and test sets\n",
        "    split_index_m = int(len(data_male) * split_ratio)\n",
        "    train_data_m = data_male[:split_index_m]\n",
        "    test_data_m = data_male[split_index_m:]\n",
        "\n",
        "\n",
        "    # Split the data female into train and test sets\n",
        "    split_index = int(len(data_female) * split_ratio)\n",
        "    train_data_f = data_female[:split_index]\n",
        "    test_data_f = data_female[split_index:]\n",
        "\n",
        "\n",
        "    train_data = pd.concat([train_data_m,train_data_f])\n",
        "    test_data = pd.concat([test_data_m,test_data_f])\n",
        "\n",
        "    return train_data, test_data"
      ],
      "metadata": {
        "id": "y91zabZGWIFU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle the dataframe to ensure randomness\n",
        "data_male = df_male.sample(frac=1)\n",
        "data_female = df_female.sample(frac=1)\n",
        "\n",
        "# Define the train-test split ratio\n",
        "split_ratio = 0.9\n",
        "\n",
        "# Split the data male into train and test sets\n",
        "#split_index_m = int(len(data_male) * split_ratio)\n",
        "#train_data_m = data_male[:split_index_m]\n",
        "#test_data_m = data_male[split_index_m:]\n",
        "\n",
        "\n",
        "# Split the data female into train and test sets\n",
        "#split_index = int(len(data_female) * split_ratio)\n",
        "#train_data_f = data_female[:split_index]\n",
        "#test_data_f = data_female[split_index:]\n",
        "\n",
        "\n",
        "#train_data = pd.concat([train_data_m,train_data_f])\n",
        "#test_data = pd.concat([test_data_m,test_data_f])\n",
        "\n",
        "train_data, test_data = SplitDataset(split_ratio)"
      ],
      "metadata": {
        "id": "7aB1CxI0UoGb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_ratio = 0.8\n",
        "train_data, test_data = SplitDataset(split_ratio)"
      ],
      "metadata": {
        "id": "gavQQVWSW0Wj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_ratio = 0.7\n",
        "train_data, test_data = SplitDataset(split_ratio)"
      ],
      "metadata": {
        "id": "1q-7dmURW4wj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GenderDataset(Dataset):\n",
        "    def __init__(self, data, image_folder_path, transform=None):\n",
        "        self.data = data\n",
        "        self.image_folder_path = image_folder_path\n",
        "        self.transform = transform\n",
        "        self.classes = ['Female', 'Male']\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = os.path.join(self.image_folder_path, self.data.iloc[idx, 0])\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "        gender = self.data.iloc[idx, 1]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, torch.tensor(gender, dtype=torch.long)"
      ],
      "metadata": {
        "id": "v2KpXG14Uqqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_transforms = transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.RandomRotation(45),\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "\n",
        "\n",
        "# Create the dataloaders for the train and test datasets\n",
        "train_dataset = GenderDataset(train_data, image_folder_path, transform=data_transforms)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True,num_workers=2)\n",
        "\n",
        "test_dataset = GenderDataset(test_data, image_folder_path, transform=data_transforms)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True,num_workers=2)\n",
        "class_names = train_dataset.classes\n",
        "\n",
        "train_dataset[0], test_dataset[0], class_names"
      ],
      "metadata": {
        "id": "A42RJywnU0kC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#show an image\n",
        "def imgshow(inp, title=None):\n",
        "  inp = inp.numpy().transpose((1, 2, 0))\n",
        "  mean = np.array([0.485, 0.456, 0.406])\n",
        "  std = np.array([0.229, 0.224, 0.225])\n",
        "  inp = std * inp + mean\n",
        "  inp = np.clip(inp, 0, 1)\n",
        "  plt.imshow(inp)\n",
        "  if title is not None:\n",
        "    plt.title(title)\n",
        "  plt.pause(0.001)\n",
        "\n",
        "# Get a batch of training data\n",
        "inputs, classes = next(iter(train_loader))\n",
        "\n",
        "# Make a grid from batch\n",
        "out = torchvision.utils.make_grid(inputs)\n",
        "\n",
        "imgshow(out, title=[class_names[x] for x in classes])"
      ],
      "metadata": {
        "id": "QuH0S6zLb3za"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the GoogLeNet model and modify it to have 2 output classes\n",
        "model_ft = models.googlenet(pretrained=True)\n",
        "num_ftrs = model_ft.fc.in_features\n",
        "model_ft.fc = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "# Define the learning rate to be used by the optimizer\n",
        "LEARNING_RATE = 0.001\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer_ft = torch.optim.Adam(model_ft.parameters(), lr=LEARNING_RATE)"
      ],
      "metadata": {
        "id": "eJwHuuy6U4Jp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Build** **Model**"
      ],
      "metadata": {
        "id": "LnKQ9cc8Vn23"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torcheval"
      ],
      "metadata": {
        "id": "KuoGRDfCLxl1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torcheval.metrics.functional import multiclass_f1_score\n",
        "\n",
        "def train_model(model, dataloaders, dataset_sizes, criterion, optimizer, use_gpu=torch.cuda.is_available(), num_epochs=10):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = model.state_dict()\n",
        "    best_acc = 0.0\n",
        "\n",
        "    test_preds = torch.tensor([], dtype=torch.long).to(\"cuda\")\n",
        "    test_labels = torch.tensor([], dtype=torch.long).to(\"cuda\")\n",
        "\n",
        "    # eval\n",
        "    epoch_loss_list=[]\n",
        "    epoch_acc_list=[]\n",
        "    f1_score_list=[]\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'test']:\n",
        "            if phase == 'train':\n",
        "                #scheduler.step()\n",
        "                model.train(True)  # Set model to training mode\n",
        "            else:\n",
        "                model.train(False)  # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for data in dataloders[phase]:\n",
        "                # get the inputs\n",
        "                inputs, labels = data\n",
        "\n",
        "                # wrap them in Variable\n",
        "                if use_gpu:\n",
        "                    inputs = Variable(inputs.cuda())\n",
        "                    labels = Variable(labels.cuda())\n",
        "                else:\n",
        "                    inputs, labels = Variable(inputs), Variable(labels)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                outputs = model(inputs)\n",
        "                \n",
        "\n",
        "                # backward + optimize only if in training phase\n",
        "                if phase == 'train':\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "                else:\n",
        "                    _, preds = torch.max(outputs.data, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.data\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "                test_preds = torch.cat((test_preds, preds), dim=0)\n",
        "                test_labels = torch.cat((test_labels, labels.data), dim=0)\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.float() / dataset_sizes[phase]\n",
        "            f1_score = multiclass_f1_score(test_preds, test_labels, num_classes=2, average='micro')\n",
        "\n",
        "            # save eval score\n",
        "            epoch_loss_list+=[epoch_loss]\n",
        "            epoch_acc_list+=[epoch_acc]\n",
        "            f1_score_list+=[f1_score]\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f} f1_score {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc, f1_score))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'test' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = model.state_dict()\n",
        "                state = {'model':model_ft.state_dict(),'optim':optimizer_ft.state_dict()}\n",
        "                torch.save(state,'/content/drive/MyDrive/save model/copy_point_googlenet_90_10_best.pth')\n",
        "                print('saving model')\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best test Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, epoch_loss_list, epoch_acc_list, f1_score_list"
      ],
      "metadata": {
        "id": "1lmF0XJDU_7x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataloders = {\n",
        "    \"train\":train_loader, \"test\":test_loader\n",
        "}\n",
        "dataset_sizes= {\n",
        "    \"train\":len(train_dataset), \"test\":len(test_dataset)\n",
        "}"
      ],
      "metadata": {
        "id": "nUgYeyUjT2hl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "use_gpu = torch.cuda.is_available()\n",
        "\n",
        "if use_gpu:\n",
        "  model_ft = model_ft.to(\"cuda\")"
      ],
      "metadata": {
        "id": "cYPE64ZoYmLx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define epochs\n",
        "NUM_EPOCHS = 10\n",
        "model_ft, epoch_loss_list, epoch_acc_list, f1_score_list = train_model(model_ft, dataloders, dataset_sizes, criterion, optimizer_ft, use_gpu, NUM_EPOCHS)"
      ],
      "metadata": {
        "id": "KlCleLuiYspw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Evaluation**"
      ],
      "metadata": {
        "id": "C4v_pxxfVaJa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def evaluate_model(model, test_loader, target_labels):\n",
        "    checkpoint = torch.load('/content/drive/MyDrive/save model/copy_point_googlenet_90_10_best.pth')\n",
        "    model.load_state_dict(checkpoint['model'])\n",
        "\n",
        "    model.eval()\n",
        "    test_preds = torch.tensor([], dtype=torch.long).to(device)\n",
        "    test_labels = torch.tensor([], dtype=torch.long).to(device)\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for inputs, labels in test_loader:\n",
        "            # wrap them in Variable\n",
        "            if use_gpu:\n",
        "                inputs = Variable(inputs.cuda())\n",
        "                labels = Variable(labels.cuda())\n",
        "            else:\n",
        "                inputs, labels = Variable(inputs), Variable(labels)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            test_preds = torch.cat((test_preds, predicted), dim=0)\n",
        "            test_labels = torch.cat((test_labels, labels), dim=0)\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print('Accuracy of the network on the test images: %d %%' % (\n",
        "        accuracy))\n",
        "    \n",
        "\n",
        "    return test_preds, test_labels"
      ],
      "metadata": {
        "id": "dJT_27ltFjTR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_labels=class_names\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "test_pred, test_label = evaluate_model(model_ft, test_loader, target_labels)"
      ],
      "metadata": {
        "id": "-lTZhgpbMMb2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the confusion matrix\n",
        "test_pred , test_label\n",
        "\n",
        "cm = confusion_matrix(test_label.cpu().numpy(), test_pred.cpu().numpy())\n",
        "fig, ax = plt.subplots(figsize=(4, 4))\n",
        "ax.imshow(cm)\n",
        "ax.grid(False)\n",
        "ax.set_xlabel('Predicted labels', fontsize=12, color='black')\n",
        "ax.set_ylabel('True labels', fontsize=12, color='black')\n",
        "ax.set_xticks(range(len(target_labels)))\n",
        "ax.set_yticks(range(len(target_labels)))\n",
        "ax.set_xticklabels(target_labels, fontsize=12, rotation=90)\n",
        "ax.set_yticklabels(target_labels, fontsize=12)\n",
        "for i in range(len(target_labels)):\n",
        "  for j in range(len(target_labels)):\n",
        "      ax.text(j, i, format(cm[i, j], 'd'), ha=\"center\", va=\"center\", color=\"white\" if cm[i, j] > (cm.max() / 2.) else \"black\", fontsize=12)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "F94A_vmLheAb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PREDICT**"
      ],
      "metadata": {
        "id": "i73xJDUyAACR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loaders = DataLoader(test_dataset, batch_size=2, shuffle=True,num_workers=2)\n",
        "checkpoint = torch.load('/content/drive/MyDrive/save model/copy_point_googlenet_90_10_best.pth')\n",
        "model_ft.load_state_dict(checkpoint['model'])\n",
        "\n",
        "# set model to evaluation mode\n",
        "model_ft.eval()\n",
        "\n",
        "# get a batch of test data\n",
        "images, labels = next(iter(test_loaders))\n",
        "\n",
        "# make predictions\n",
        "with torch.no_grad():\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "    outputs = model_ft(images)\n",
        "    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "# display results\n",
        "for i in range(images.shape[0]):\n",
        "    image = images[i].cpu().numpy().transpose((1, 2, 0))\n",
        "    label = class_names[labels[i]]\n",
        "    pred = class_names[preds[i]]\n",
        "    \n",
        "    fig, ax = plt.subplots(figsize=(4, 4))\n",
        "    plt.imshow(image)\n",
        "    plt.title(f'True Label: {label}, Predicted Label: {pred}')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "tl2MpZd5WYm_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}